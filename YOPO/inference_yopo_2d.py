#!/usr/bin/env python3
import rospy
import torch
import numpy as np
import cv2
import time
import os
import sys

# ROS æ¶ˆæ¯ç±»å‹
from nav_msgs.msg import Odometry
from geometry_msgs.msg import PoseStamped, Twist
from sensor_msgs.msg import Image, PointCloud2, PointField
from sensor_msgs import point_cloud2
import std_msgs.msg

# æ•°å­¦å·¥å…·
from scipy.spatial.transform import Rotation as R

# å¼•å…¥ä½ çš„é¡¹ç›®æ¨¡å—
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from config.config import cfg
from policy.rgb_yopo_network import CMCL_YOPO_Network
from policy.state_transform import StateTransform

class YopoInferenceNode:
    def __init__(self):
        rospy.init_node('yopo_inference', anonymous=False)
        
        # --- 1. å‚æ•°é…ç½® ---
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.height = 32   # 2D åœºæ™¯é«˜åº¦
        self.width = 160
        self.max_dist = 20.0 # æ·±åº¦å›¾æœ€å¤§è·ç¦»
        self.traj_time = cfg["sgm_time"]
        
        # æƒé‡è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„)
        self.ckpt_path = rospy.get_param("~weights", "./saved/YOPO_5/epoch49.pth")
        
        # ç›®æ ‡ç‚¹ (å…¨å±€åæ ‡)
        self.goal_world = np.array([10, 0.0]) # é»˜è®¤å‰æ–¹10ç±³
        self.has_odom = False
        
        # è½¦è¾†å½“å‰çŠ¶æ€ (å…¨å±€)
        self.cur_pos = np.zeros(2) # x, y
        self.cur_yaw = 0.0
        self.cur_vel = np.zeros(2) # vx, vy (Body Frame)
        
        # --- 2. åŠ è½½æ¨¡å‹ ---
        print(f"Loading model from {self.ckpt_path}...")
        self.policy = CMCL_YOPO_Network().to(self.device)
        self.state_transform = StateTransform()
        
        try:
            # åŠ è½½æƒé‡
            state_dict = torch.load(self.ckpt_path, map_location=self.device)
            self.policy.load_state_dict(state_dict, strict=False) 
            self.policy.eval()
            print("âœ… Model loaded successfully!")
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            exit(1)

        # --- 3. ROS é€šä¿¡ ---
        # Subscribers
        self.sub_odom = rospy.Subscriber("/odom", Odometry, self.cb_odom, queue_size=1)
        self.sub_depth = rospy.Subscriber("/camera/depth/image", Image, self.cb_depth, queue_size=1, tcp_nodelay=True)
        self.sub_goal = rospy.Subscriber("/move_base_simple/goal", PoseStamped, self.cb_goal, queue_size=1)
        
        # Publishers
        self.pub_traj = rospy.Publisher("/yopo/traj_vis", PointCloud2, queue_size=1) # å¯è§†åŒ–è½¨è¿¹
        self.pub_cmd = rospy.Publisher("/cmd_vel", Twist, queue_size=1) # æ§åˆ¶æŒ‡ä»¤

        print("ğŸš€ YOPO 2D Inference Node Started!")
        rospy.spin()

    def cb_goal(self, msg):
        self.goal_world = np.array([msg.pose.position.x, msg.pose.position.y])
        print(f"New Goal Received: {self.goal_world}")

    def cb_odom(self, msg):
        # æå–ä½ç½®
        self.cur_pos = np.array([msg.pose.pose.position.x, msg.pose.pose.position.y])
        
        # æå–å§¿æ€ (Quaternion -> Yaw)
        q = msg.pose.pose.orientation
        rot = R.from_quat([q.x, q.y, q.z, q.w])
        self.cur_yaw = rot.as_euler('zyx')[0]
        
        # æå–é€Ÿåº¦ (Body Frame)
        # æ³¨æ„: ROS Odometry çš„ twist.linear é€šå¸¸æ˜¯ Body Frame (child_frame_id)
        self.cur_vel = np.array([msg.twist.twist.linear.x, msg.twist.twist.linear.y])
        
        self.has_odom = True

    @torch.inference_mode()
    def cb_depth(self, msg):
       
        if not self.has_odom: return
        t0 = time.time()

        # --- 1. æ·±åº¦å›¾é¢„å¤„ç† ---
        # å‡è®¾è¾“å…¥æ˜¯ 32FC1 (æµ®ç‚¹æ·±åº¦, å•ä½ç±³)
        # å¦‚æœæ˜¯ uint16 (æ¯«ç±³)ï¼Œéœ€è¦é™¤ä»¥ 1000.0
        if msg.encoding == "32FC1":
            depth_np = np.frombuffer(msg.data, dtype=np.float32).reshape(msg.height, msg.width)
        elif msg.encoding == "16UC1":
            depth_np = np.frombuffer(msg.data, dtype=np.uint16).reshape(msg.height, msg.width) / 1000.0
        else:
            return

        # Resize åˆ°ç½‘ç»œè¾“å…¥å°ºå¯¸ (160x32)
        depth_resized = cv2.resize(depth_np, (self.width, self.height), interpolation=cv2.INTER_NEAREST)
        
        # å½’ä¸€åŒ– & æˆªæ–­
        depth_norm = np.clip(depth_resized / self.max_dist, 0.0, 1.0)
        
        # å †å æˆ 3 é€šé“ [3, 32, 160] (é€‚é…ä½ çš„ Dataset é€»è¾‘)
        depth_3ch = np.stack([depth_norm] * 3, axis=0)
        
        # è½¬ Tensor [1, 3, 32, 160]
        depth_tensor = torch.from_numpy(depth_3ch).float().unsqueeze(0).to(self.device)

        # --- 2. çŠ¶æ€å‘é‡é¢„å¤„ç† (Body Frame) ---
        # è®¡ç®—å±€éƒ¨ç›®æ ‡ç‚¹ (Goal in Body Frame)
        # å‘é‡ = Goal - Pos
        vec_w = self.goal_world - self.cur_pos
        # æ—‹è½¬åˆ° Body ç³»: R_inv * vec
        c, s = np.cos(self.cur_yaw), np.sin(self.cur_yaw)
        R_inv = np.array([[c, s], [-s, c]]) # 2D æ—‹è½¬çŸ©é˜µçš„é€†
        goal_b = R_inv @ vec_w
        
        # é™åˆ¶ Goal è·ç¦» (é˜²æ­¢è¿‡å¤§æ•°å€¼)
        if np.linalg.norm(goal_b) > 5.0:
            goal_b = goal_b / np.linalg.norm(goal_b) * 5.0

        # ç»„è£… Obs: [vx, vy, ax, ay, gx, gy]
        # å‡è®¾å½“å‰åŠ é€Ÿåº¦ ax, ay ä¸º 0 (æˆ–è€…ä½ å¯ä»¥ä» IMU è·å–)
        acc_b = np.array([0.0, 0.0]) 
        
        obs_np = np.hstack([self.cur_vel, acc_b, goal_b]).astype(np.float32)
        obs_tensor = torch.from_numpy(obs_np).unsqueeze(0).to(self.device)
        
        # å½’ä¸€åŒ– Obs
        # obs_tensor = self.state_transform.normalize_obs(obs_tensor) (å¦‚æœè®­ç»ƒæ—¶ç”¨äº†è¿™ä¸ª)

        # --- 3. ç½‘ç»œæ¨ç† ---
        # endstate: [1, 6] (px, py, vx, vy, ax, ay)
        # score: [1, 1]
        endstate_norm, score = self.policy.inference(depth_tensor, obs_tensor)
        
        # --- 4. ç”Ÿæˆè½¨è¿¹ & æ§åˆ¶ ---
        # è¿˜åŸç‰©ç†çŠ¶æ€ (Body Frame)
        # æ³¨æ„: è¿™é‡Œçš„ pred_to_endstate_2d éœ€è¦æ˜¯ä½ æœ€æ–°ä¿®æ”¹è¿‡çš„é‚£ä¸ªå•è½¨è¿¹ç‰ˆæœ¬
        # å®ƒè¿”å›çš„æ˜¯ Body Frame ä¸‹çš„ [1, 3, 3] (Pos, Vel, Acc) æˆ–è€…æ˜¯ [1, 6]
        # æˆ‘ä»¬è¿™é‡Œå‡è®¾ inference å†…éƒ¨å·²ç»è°ƒç”¨äº† pred_to_endstate_2dï¼Œè¿”å›çš„æ˜¯ç‰©ç†å€¼ [1, 3, 3]
        # å¦‚æœ inference è¿”å›çš„æ˜¯ normalized çš„ï¼Œè¿™é‡Œéœ€è¦æ‰‹åŠ¨è½¬æ¢ä¸€ä¸‹
        
        # å‡è®¾ inference è¿”å›çš„æ˜¯å·²ç»è§£ç®—å¥½çš„ç‰©ç†çŠ¶æ€ (Body Frame)
        # endstate: [Batch, 3, 3] -> [Pos(x,y,z), Vel, Acc]
        
        # å¦‚æœä½ çš„ inference æ²¡æœ‰åšç‰©ç†è½¬æ¢ï¼Œåœ¨è¿™é‡Œåšï¼š
        # endstate_phys = self.policy.pred_to_endstate_2d(endstate_norm)
        endstate_phys = endstate_norm # å‡è®¾ inference é‡Œå·²ç»è½¬å¥½äº†
        
        # ç”Ÿæˆå¤šé¡¹å¼è½¨è¿¹ç‚¹
        traj_points = self.generate_poly_traj(self.cur_vel, acc_b, endstate_phys[0])
        
        # å‘å¸ƒå¯è§†åŒ–
        self.publish_traj(traj_points, score.item())
        
        # å‘å¸ƒæ§åˆ¶ (ç®€å•çš„çº¯è¿½è¸ª Pure Pursuit æˆ– PID)
        self.publish_control(traj_points)
        
        t_process = (time.time() - t0) * 1000
        
        # print(f"Inference Time: {t_process:.2f}ms | Score: {score.item():.4f}")

    def generate_poly_traj(self, start_vel, start_acc, end_state):
        """
        ç”Ÿæˆ 5 é˜¶å¤šé¡¹å¼è½¨è¿¹ç”¨äºå¯è§†åŒ–å’Œæ§åˆ¶
        end_state: [3, 3] (Pos, Vel, Acc) (åŒ…å«Zè½´0) æˆ– [6]
        """
        # æ„é€  Start (Body Frame, Pos=0)
        p0 = np.zeros(2)
        v0 = start_vel
        a0 = start_acc
        
        # è§£æ End
        # å¦‚æœ end_state æ˜¯ [3, 3] (Pos, Vel, Acc)
        if end_state.shape == (3, 3):
            p1 = end_state[0, :2].cpu().numpy()
            v1 = end_state[1, :2].cpu().numpy()
            a1 = end_state[2, :2].cpu().numpy()
        else:
            # å¦‚æœæ˜¯ [6] (px, py, vx, vy, ax, ay)
            e = end_state.cpu().numpy()
            p1, v1, a1 = e[0:2], e[2:4], e[4:6]

        T = self.traj_time
        
        # æ±‚è§£ 5 é˜¶å¤šé¡¹å¼ç³»æ•° (Quintic Polynomial)
        # p(t) = c0 + c1*t + c2*t^2 + c3*t^3 + c4*t^4 + c5*t^5
        # å·²çŸ¥è¾¹ç•Œæ¡ä»¶æ±‚è§£
        # è¿™é‡Œç”¨ç®€åŒ–çš„çŸ©é˜µå½¢å¼æ±‚è§£ X å’Œ Y
        
        def solve_quintic(x0, v0, a0, x1, v1, a1, T):
            A = np.array([
                [0, 0, 0, 0, 0, 1], # p(0)
                [0, 0, 0, 0, 1, 0], # v(0)
                [0, 0, 0, 2, 0, 0], # a(0)
                [T**5, T**4, T**3, T**2, T, 1], # p(T)
                [5*T**4, 4*T**3, 3*T**2, 2*T, 1, 0], # v(T)
                [20*T**3, 12*T**2, 6*T, 2, 0, 0]  # a(T)
            ])
            b = np.array([x0, v0, a0, x1, v1, a1])
            # coeffs: [c5, c4, c3, c2, c1, c0]
            return np.linalg.solve(A, b)

        coeffs_x = solve_quintic(p0[0], v0[0], a0[0], p1[0], v1[0], a1[0], T)
        coeffs_y = solve_quintic(p0[1], v0[1], a0[1], p1[1], v1[1], a1[1], T)
        
        # é‡‡æ · 20 ä¸ªç‚¹
        t = np.linspace(0, T, 20)
        
        # è®¡ç®—åæ ‡ (Horners method or matrix)
        # p = c5*t^5 + ...
        poly = lambda c, t: c[0]*t**5 + c[1]*t**4 + c[2]*t**3 + c[3]*t**2 + c[4]*t + c[5]
        
        xs = poly(coeffs_x, t)
        ys = poly(coeffs_y, t)
        
        return np.stack([xs, ys], axis=1)

    def publish_traj(self, points, score):
        # æ„é€  PointCloud2 (Body Frame / base_link)
        # points: [N, 2]
        z = np.zeros((points.shape[0], 1))
        # intensity ç”¨ score å¡«å……
        i = np.full((points.shape[0], 1), score) 
        
        pc_data = np.hstack([points, z, i]).astype(np.float32)
        
        header = std_msgs.msg.Header()
        header.stamp = rospy.Time.now()
        header.frame_id = "base_link" # å…³é”®ï¼šè½¨è¿¹æ˜¯åœ¨è½¦èº«åæ ‡ç³»ä¸‹çš„
        
        fields = [
            PointField('x', 0, PointField.FLOAT32, 1),
            PointField('y', 4, PointField.FLOAT32, 1),
            PointField('z', 8, PointField.FLOAT32, 1),
            PointField('intensity', 12, PointField.FLOAT32, 1)
        ]
        
        msg = point_cloud2.create_cloud(header, fields, pc_data)
        self.pub_traj.publish(msg)

    def publish_control(self, points):
        # ç®€å•çš„çº¯è¿½è¸ª (Pure Pursuit) æˆ– å–ç‚¹æ§åˆ¶
        # å–ç¬¬ 5 ä¸ªç‚¹ (çº¦ 0.2s - 0.4s å¤„) ä½œä¸ºé¢„ç„ç‚¹
        lookahead_idx = min(5, len(points)-1)
        target = points[lookahead_idx] # [x, y]
        
        # è®¡ç®—æ›²ç‡ / è§’é€Ÿåº¦
        # w = 2 * y / L^2 * v
        L2 = target[0]**2 + target[1]**2
        if L2 < 0.01: 
            w = 0
            v = 0
        else:
            # æœŸæœ›é€Ÿåº¦ (å¯ä»¥æ ¹æ® curvature åŠ¨æ€è°ƒæ•´)
            v_cmd = 1.0 # å‡è®¾æ’å®šé€Ÿåº¦ï¼Œæˆ–è€…ç”¨ç½‘ç»œé¢„æµ‹çš„ v1
            w_cmd = 2 * target[1] / L2 * v_cmd
        
        cmd = Twist()
        cmd.linear.x = v_cmd
        cmd.angular.z = np.clip(w_cmd, -1.0, 1.0) # é™åˆ¶è§’é€Ÿåº¦
        self.pub_cmd.publish(cmd)

if __name__ == "__main__":
    try:
        node = YopoInferenceNode()
    except rospy.ROSInterruptException:
        pass